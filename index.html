<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Smile Trigger Sound</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      margin: 0;
      font-family: sans-serif;
      background: #071827;
      color: #cfe9ff;
      text-align: center;
    }
    h1 {
      padding: 20px;
      font-size: 24px;
    }
    video {
      width: 100%;
      max-width: 400px;
      border: 4px solid #2aa1c3;
      margin-top: 20px;
      border-radius: 12px;
    }
    button {
      margin: 20px;
      padding: 14px 28px;
      font-size: 18px;
      background: #2aa1c3;
      color: #071827;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      transition: all 0.2s ease;
    }
    button:hover {
      background: #88d2e8;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
  <h1>Smile to Trigger Sound</h1>
  <button id="startBtn">Start Camera</button>
  <video id="video" autoplay muted playsinline></video>

  <script>
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    async function playSmileSound() {
      const osc = audioCtx.createOscillator();
      const gain = audioCtx.createGain();
      osc.type = "triangle";
      osc.frequency.value = 440;
      gain.gain.value = 0.2;
      osc.connect(gain).connect(audioCtx.destination);
      osc.start();
      osc.stop(audioCtx.currentTime + 0.3);
    }

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" }, audio: false
        });
        video.srcObject = stream;
        video.setAttribute("playsinline", true);
        video.setAttribute("autoplay", true);
        video.setAttribute("muted", true);
        await video.play();
        return stream;
      } catch (err) {
        alert("Camera access failed: " + err.message);
      }
    }

    startBtn.addEventListener('click', async () => {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models'),
        faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models')
      ]);

      const stream = await startCamera();
      if (!stream) return;

      video.addEventListener('loadeddata', () => {
        const canvas = faceapi.createCanvasFromMedia(video);
        document.body.append(canvas);
        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        faceapi.matchDimensions(canvas, displaySize);

        let lastSmile = false;

        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceExpressions();

          const resized = faceapi.resizeResults(detections, displaySize);
          canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resized);

          if (detections.length > 0) {
            const smileProb = detections[0].expressions.happy;
            if (smileProb > 0.8 && !lastSmile) {
              playSmileSound();
              lastSmile = true;
              setTimeout(() => lastSmile = false, 1000);
            }
          }
        }, 500);
      });
    });
  </script>
</body>
</html>
