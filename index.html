<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Smile Trigger Sound</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body { margin:0; font-family:sans-serif; background:#071827; color:#cfe9ff; text-align:center; }
    video { width:100%; max-width:400px; border:4px solid #2aa1c3; margin-top:20px; }
    button { margin:20px; padding:12px 24px; font-size:18px; background:#2aa1c3; color:#071827; border:none; border-radius:12px; cursor:pointer; }
  </style>
</head>
<body>
  <h1>Smile to Trigger Sound</h1>
  <button id="startBtn">Start Camera</button>
  <video id="video" autoplay muted playsinline></video>

<script>
const video = document.getElementById('video');
const startBtn = document.getElementById('startBtn');
const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

async function playSmileSound() {
  const osc = audioCtx.createOscillator();
  const gain = audioCtx.createGain();
  osc.type = "triangle";
  osc.frequency.value = 440;
  gain.gain.value = 0.2;
  osc.connect(gain).connect(audioCtx.destination);
  osc.start();
  osc.stop(audioCtx.currentTime + 0.3);
}

startBtn.addEventListener('click', async () => {
  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models'),
    faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models')
  ]);

  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;

  video.addEventListener('play', () => {
    const canvas = faceapi.createCanvasFromMedia(video);
    document.body.append(canvas);
    const displaySize = { width: video.width, height: video.height };
    faceapi.matchDimensions(canvas, displaySize);

    let lastSmile = false;

    setInterval(async () => {
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
      const resized = faceapi.resizeResults(detections, displaySize);
      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
      faceapi.draw.drawDetections(canvas, resized);

      if (detections.length > 0) {
        const smileProb = detections[0].expressions.happy;
        if (smileProb > 0.8 && !lastSmile) {
          playSmileSound();
          lastSmile = true;
          setTimeout(() => lastSmile = false, 1000); // debounce
        }
      }
    }, 500);
  });
});
</script>
</body>
</html>
